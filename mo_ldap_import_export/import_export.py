# SPDX-FileCopyrightText: Magenta ApS <https://magenta.dk>
# SPDX-License-Identifier: MPL-2.0
import asyncio
import json
from collections.abc import Awaitable
from collections.abc import Callable
from contextlib import ExitStack
from functools import wraps
from typing import Any
from typing import TypeVar
from uuid import UUID
from uuid import uuid4

import structlog
from fastramqpi.ramqp.depends import handle_exclusively_decorator
from ldap3 import Connection
from more_itertools import only
from structlog.contextvars import bound_contextvars

from .autogenerated_graphql_client.input_types import EmployeeFilter
from .autogenerated_graphql_client.input_types import ITSystemFilter
from .autogenerated_graphql_client.input_types import ITUserFilter
from .config import LDAP2MOMapping
from .config import Settings
from .converters import LdapConverter
from .customer_specific_checks import ExportChecks
from .customer_specific_checks import ImportChecks
from .dataloaders import DN
from .dataloaders import DataLoader
from .dataloaders import NoGoodLDAPAccountFound
from .environments.main import get_or_create_job_function_uuid
from .exceptions import DryRunException
from .exceptions import IncorrectMapping
from .exceptions import SkipObject
from .ldap import apply_discriminator
from .ldap import filter_dns
from .ldap import get_ldap_object
from .moapi import MOAPI
from .moapi import Verb
from .moapi import get_primary_engagement
from .models import Address
from .models import Class
from .models import Employee
from .models import Engagement
from .models import ITSystem
from .models import ITUser
from .models import MOBase
from .models import OrganisationUnit
from .models import Termination
from .models import Validity
from .types import EmployeeUUID
from .types import OrgUnitUUID
from .utils import ensure_list
from .utils import mo_today

logger = structlog.stdlib.get_logger()


T = TypeVar("T", covariant=True)


def with_exitstack(
    func: Callable[..., Awaitable[T]],
) -> Callable[..., Awaitable[T]]:
    """Inject an exit-stack into decorated function.

    Args:
        func: The function to inject the exit-stack into.

    Returns:
        Decorated function that takes the exit-stack as an argument.
    """

    @wraps(func)
    async def inner(*args: Any, **kwargs: Any) -> Any:
        with ExitStack() as exit_stack:
            return await func(*args, **kwargs, exit_stack=exit_stack)

    return inner


async def sync_JobTitleFromADToMO(
    moapi: MOAPI, ldap_connection: Connection, dn: DN
) -> None:
    # NOTE: This function is scheduled for removal, see #62802
    ldap_object = await get_ldap_object(
        # The attributes are hardcoded for the only customer using this endpoint
        ldap_connection=ldap_connection,
        dn=dn,
        attributes={"hkStsuuid", "title"},
    )
    assert hasattr(ldap_object, "hkStsuuid")
    assert hasattr(ldap_object, "title")

    job_function = UUID(
        await get_or_create_job_function_uuid(
            moapi, ldap_object.title, default="Medarbejder"
        )
    )

    result = await moapi.graphql_client.read_engagements_by_employee_uuid(
        ldap_object.hkStsuuid
    )
    engagements = [x.current for x in result.objects if x.current is not None]
    await asyncio.gather(
        *[
            moapi.graphql_client.set_job_title(
                uuid=obj.uuid,
                from_=obj.validity.from_,
                to=obj.validity.to,
                job_function=job_function,
            )
            for obj in engagements
        ]
    )


class SyncTool:
    def __init__(
        self,
        dataloader: DataLoader,
        converter: LdapConverter,
        export_checks: ExportChecks,
        import_checks: ImportChecks,
        settings: Settings,
        ldap_connection: Connection,
    ) -> None:
        self.dataloader: DataLoader = dataloader
        self.converter: LdapConverter = converter
        self.export_checks: ExportChecks = export_checks
        self.import_checks: ImportChecks = import_checks
        self.settings: Settings = settings
        self.ldap_connection: Connection = ldap_connection

    async def perform_export_checks(self, employee_uuid: UUID) -> None:
        """
        Perform a number of customer-specific checks. Raising IgnoreChanges() if a
        check fails
        """

        # Check that the employee has an it-user with user_key = it_user_to_check
        await self.export_checks.check_it_user(
            employee_uuid,
            self.settings.it_user_to_check,
        )

    async def perform_import_checks(self, dn: DN, json_key: str) -> bool:
        if self.settings.check_holstebro_ou_issue_57426:  # pragma: no cover
            return await self.import_checks.check_holstebro_ou_is_externals_issue_57426(
                self.settings.check_holstebro_ou_issue_57426,
                dn,
                json_key,
            )
        return True

    async def render_ldap2mo(
        self, uuid: EmployeeUUID, dn: DN | None
    ) -> dict[str, list[Any]]:
        await self.perform_export_checks(uuid)

        mo2ldap_template = self.settings.conversion_mapping.mo2ldap
        assert mo2ldap_template is not None
        template = self.converter.environment.from_string(mo2ldap_template)
        result = await template.render_async({"uuid": uuid, "dn": dn})
        logger.debug("Rendered jinja template", uuid=uuid, dn=dn, result=result)
        parsed = json.loads(result)
        logger.debug(
            "Parsed jinja template", uuid=uuid, dn=dn, result=result, parsed=parsed
        )
        assert isinstance(parsed, dict)
        assert all(isinstance(key, str) for key in parsed)
        # Convert None's to empty lists to avoid writing "None" in LDAP
        # Whenever a None is templated out we empty the value in LDAP
        parsed = {key: [] if value is None else value for key, value in parsed.items()}
        # TODO: force users to configure as list instead of implicitly
        # converting (very confusing).
        # assert all(isinstance(value, list) for value in parsed.values())
        return {key: ensure_list(value) for key, value in parsed.items()}

    async def ensure_ituser_link(self, uuid: EmployeeUUID, dn: DN) -> None:
        # Check if we even dare create a DN
        raw_it_system_uuid = await self.dataloader.moapi.get_ldap_it_system_uuid()
        if raw_it_system_uuid is None:
            return None
        it_system_uuid = UUID(raw_it_system_uuid)

        # If the LDAP ITSystem exists, we want to create a binding to our newly
        # generated (and created) DN, such that it can be correlated in the future.
        #
        # NOTE: This may not be executed if the program crashes after creating the LDAP
        #       account, but before creating this ituser link.
        #       Thus the current code is not robust and may fail at any time.
        #       The appropriate solution here is either to ensure that the LDAP account
        #       and the ituser link are created atomically or to introduce a multi-stage
        #       commit solution to the integration.
        #       One practical solution may be to entirely eliminate the need for these
        #       ituser links by allocating a field in LDAP for the MO UUID and using
        #       that field to link MO and LDAP accounts together.
        #       An alternative solution may involve writing a temporary dummy value to
        #       LDAP on the initial create which can be detected later to ensure that
        #       creation is completed even if the program crashes at an inopportune
        #       time. - The risk of this approach is that we have bad values in LDAP,
        #       which may be synchronized by other listeners on LDAP, and thus have
        #       unforseen consequences.
        logger.info("No ITUser found, ensuring one exists to correlate with DN")
        # Get its unique ldap uuid
        # TODO: Get rid of this code and operate on EntityUUIDs thoughout
        unique_uuid = await self.dataloader.ldapapi.get_ldap_unique_ldap_uuid(dn)
        logger.info("LDAP UUID found for DN", dn=dn, ldap_uuid=unique_uuid)
        result = await self.dataloader.moapi.graphql_client.read_ituser_uuid(
            ITUserFilter(
                user_keys=[str(unique_uuid)],
                itsystem=ITSystemFilter(uuids=[it_system_uuid]),
                employee=EmployeeFilter(uuids=[uuid]),
            )
        )
        # If the link already exists, do nothing
        if len(result.objects) != 0:
            logger.info("Not creating link as it already exists")
            return
        logger.info("Creating link as it is missing")
        # If the link does not exist, create it
        it_user = ITUser(
            user_key=str(unique_uuid),
            itsystem=it_system_uuid,
            person=uuid,
            validity=Validity(start=mo_today(), end=None),
            org_unit=None,
        )
        await self.dataloader.moapi.create_ituser(it_user)

    async def may_create_user_given_orgunit_location(self, uuid: EmployeeUUID) -> bool:
        create_user_trees = set(self.settings.create_user_trees)
        # Empty set, means nothing to check, which means we will create
        if not create_user_trees:
            logger.debug("create_user_trees not configured, allowing create")
            return True

        primary_engagement_uuid = await get_primary_engagement(
            self.dataloader.moapi.graphql_client, uuid
        )
        if primary_engagement_uuid is None:
            logger.info(
                "create_user_trees configured, but no primary engagement, skipping"
            )
            return False

        fetched_engagement = await self.dataloader.moapi.load_mo_engagement(
            primary_engagement_uuid, end=None
        )
        if fetched_engagement is None:
            logger.info("create_user_trees engagement is not current or future")
            return False

        org_unit_uuid = fetched_engagement.org_unit
        if org_unit_uuid in create_user_trees:
            return True

        # Converting ancestors to a set, as we do not care which ancestor is found
        ancestors = set(
            await self.dataloader.moapi.get_ancestors(OrgUnitUUID(org_unit_uuid))
        )
        # If any ancestor is overlapping with the create_user_trees UUIDs we match
        overlap = create_user_trees.intersection(ancestors)
        return bool(overlap)

    @with_exitstack
    async def listen_to_changes_in_employees(
        self,
        uuid: EmployeeUUID,
        exit_stack: ExitStack,
        dry_run: bool = False,
    ) -> dict[str, list[Any]]:
        """Synchronize employee data from MO to LDAP.

        Args:
            uuid: UUID of the changed employee.
            exit_stack: The injected exit-stack.
        """
        exit_stack.enter_context(bound_contextvars(uuid=str(uuid)))
        logger.info("Registered change in an employee")

        mo2ldap_template = self.settings.conversion_mapping.mo2ldap
        if not mo2ldap_template:
            logger.info("listen_to_changes_in_employees called without mapping")
            return {}

        try:
            best_dn = await self.dataloader._find_best_dn(uuid)
        except NoGoodLDAPAccountFound:
            return {}

        # No DN set, means we are creating
        if best_dn is None:
            # If dry-running we do not want to generate real DNs in LDAP
            is_ok = await self.may_create_user_given_orgunit_location(uuid)
            if not is_ok:
                logger.info("Primary engagement OU outside create_user_trees, skipping")
                return {}

        exit_stack.enter_context(bound_contextvars(dn=best_dn))
        try:
            ldap_desired_state = await self.render_ldap2mo(uuid, best_dn)
        except SkipObject:
            logger.info("Not writing to LDAP as skip was requested")
            return {}

        if not ldap_desired_state:
            logger.info("Not writing to LDAP as changeset is empty")
            return {}

        create = False
        if best_dn is None:
            create = True
            common_name = (
                only(ldap_desired_state["cn"]) if "cn" in ldap_desired_state else None
            )
            # TODO: When we are creating a user we should make sure we have a reference
            #       to it, the ituser-link in the below attempts to create this link,
            #       however there is no guarantee that the program does not crash between
            #       these two lines, and as such it does *NOT* work as a robust link.
            #       This has however been an issue since the introduction of the
            #       integration so it has always been broken, and we have always risked
            #       leaking LDAP accounts.
            #       The good solution is to somehow link the LDAP account to MO with
            #       values set during its creation, ensuring we can find them, even if
            #       we crash immediately after the creation of the account.
            best_dn = await self.dataloader.make_mo_employee_dn(uuid, common_name)

        current_dn = await self.dataloader.ldapapi.ensure_ldap_object(
            best_dn,
            ldap_desired_state,
            self.settings.ldap_object_class,
            create,
            dry_run,
        )
        if dry_run:
            raise DryRunException("No changes", best_dn, details={})
        await self.ensure_ituser_link(uuid, current_dn)
        return ldap_desired_state

    async def fetch_uuid_object(
        self, uuid: UUID, mo_class: type[MOBase]
    ) -> MOBase | None:
        # This type is not handled by this function
        assert not issubclass(mo_class, Termination)

        if issubclass(mo_class, Address):
            return await self.dataloader.moapi.load_mo_address(
                uuid, current_objects_only=False
            )
        if issubclass(mo_class, Engagement):
            return await self.dataloader.moapi.load_mo_engagement(
                uuid, start=None, end=None
            )
        if issubclass(mo_class, ITUser):
            return await self.dataloader.moapi.load_mo_it_user(
                uuid, current_objects_only=False
            )
        if issubclass(mo_class, ITSystem):
            return await self.dataloader.moapi.load_mo_it_system(
                uuid, current_objects_only=False
            )
        if issubclass(mo_class, Class):
            return await self.dataloader.moapi.load_mo_class(
                uuid, current_objects_only=False
            )
        if issubclass(mo_class, Employee):
            return await self.dataloader.moapi.load_mo_employee(
                uuid, current_objects_only=False
            )
        if issubclass(mo_class, OrganisationUnit):
            return await self.dataloader.moapi.load_mo_org_unit(
                uuid, current_objects_only=False
            )
        raise AssertionError(f"Unknown mo_class: {mo_class}")

    def get_mapping(self, json_key: str) -> LDAP2MOMapping:
        assert self.settings.conversion_mapping.ldap_to_mo is not None
        try:
            return self.settings.conversion_mapping.ldap_to_mo[json_key]
        except KeyError as error:  # pragma: no cover
            raise IncorrectMapping(
                f"Missing '{json_key}' in mapping 'ldap_to_mo'"
            ) from error

    async def format_converted_object(
        self,
        converted_object: MOBase | Termination,
        mo_attributes: set[str],
    ) -> tuple[MOBase | Termination, Verb] | None:
        """
        for Address and Engagement objects:
            Loops through the objects, and sets the uuid if an existing matching object
            is found
        for ITUser objects:
            Loops through the objects and removes it if an existing matchin object is
            found
        for all other objects:
            returns the input list of converted_objects
        """
        if isinstance(converted_object, Termination):
            return (converted_object, Verb.TERMINATE)

        mo_class = type(converted_object)
        mo_object = await self.fetch_uuid_object(converted_object.uuid, mo_class)
        if mo_object is None:
            return converted_object, Verb.CREATE

        # Convert our objects to dicts
        mo_object_dict_to_upload = mo_object.dict()
        # Need to by_alias=True to extract the terminate_ field as its alias,
        # _terminate_. Only the *intersection* of attribute names from
        # mo_object_dict_to_upload and converted_mo_object_dict are used.
        converted_mo_object_dict = converted_object.dict(by_alias=True)

        # Update the existing MO object with the converted values
        # NOTE: UUID cannot be updated as it is used to decide what we update
        # NOTE: objectClass is removed as it is an LDAP implemenation detail
        # TODO: Why do we not update validity???
        mo_attributes = mo_attributes - {"validity", "uuid", "objectClass"}
        # Only copy over keys that exist in both sets
        mo_attributes = mo_attributes & converted_mo_object_dict.keys()

        update_values = {
            key: converted_mo_object_dict[key]
            for key in mo_attributes
            # Only include values that actually need to be updated
            if mo_object_dict_to_upload[key] != converted_mo_object_dict[key]
        }
        # If an object is identical to the one already there, it does not need
        # to be uploaded.
        if not update_values:
            logger.info("Converted object is identical to existing object, skipping")
            return None

        logger.info(
            "Setting values on upload dict",
            uuid=mo_object_dict_to_upload["uuid"],
            values=update_values,
            old_values={key: mo_object_dict_to_upload[key] for key in update_values},
        )

        mo_object_dict_to_upload.update(update_values)
        converted_object_uuid_checked = mo_class(**mo_object_dict_to_upload)

        # We found a match, so we are editing the object we matched
        return converted_object_uuid_checked, Verb.EDIT

    @with_exitstack
    async def import_single_user(self, dn: DN, exit_stack: ExitStack) -> None:
        """Imports a single user from LDAP into MO.

        Args:
            dn: The DN that triggered our event changed in LDAP.
        """
        exit_stack.enter_context(bound_contextvars(dn=dn))

        logger.info("Importing user")

        if not self.settings.conversion_mapping.ldap_to_mo:
            logger.info("import_single_user called without mapping")
            return

        # Get the employee's UUID (if they exists)
        employee_uuid = await self.dataloader.find_mo_employee_uuid(dn)
        if employee_uuid:
            # If we found an employee UUID, we want to use that to find all DNs
            dns = await self.dataloader.find_mo_employee_dn(employee_uuid)
        else:  # We did not find an employee UUID
            ldap_to_mo = self.settings.conversion_mapping.ldap_to_mo
            assert ldap_to_mo is not None
            # Check if we wish to create the employee or not
            if "Employee" not in ldap_to_mo:  # pragma: no cover
                logger.info(
                    "Employee not found in MO, and no ldap_to_mo Employee mapping"
                )
                return
            employee_mapping = ldap_to_mo["Employee"]

            create_employee = employee_mapping.import_to_mo == "true"
            if not create_employee:
                # If we do not want to create the employee and it does not exist, there
                # is no more to be done, as we cannot create dependent resources with no
                # employee to attach them to.
                logger.info("Employee not found in MO, and not configured to create it")
                return
            logger.info("Employee not found, but configured to create it")

            # As we wish to create an employee, we need to generate an UUID for it
            employee_uuid = EmployeeUUID(uuid4())
            logger.info(
                "Employee not found in MO, generated UUID", employee_uuid=employee_uuid
            )
            # At this point employee_uuid is always set

            # We want to create our employee using the best possible LDAP account.
            # By default, we will use the account that was provided to us in the event.
            dns = {dn}

            # However we may be able to find other accounts using the CPR number on the
            # event triggered account, by searching for the CPR number in all of LDAP.
            # Note however, that this will only succeed if there is a CPR number field.
            cpr_number = await self.dataloader.ldapapi.dn2cpr(dn)
            # Only attempt to load accounts if we have a CPR number to do so with
            if cpr_number:
                dns = await self.dataloader.ldapapi.cpr2dns(cpr_number)

        # At this point 'employee_uuid' is an UUID that may or may not be in MO
        # At this point 'dns' is a list of LDAP account DNs

        # We always want to synchronize from the best LDAP account, instead of just
        # synchronizing from the last LDAP account that has been touched.
        # Thus we process the list of DNs found for the user to pick the best one.
        dns = await filter_dns(self.settings, self.ldap_connection, dns)
        best_dn = await apply_discriminator(
            self.settings,
            self.ldap_connection,
            self.dataloader.moapi,
            employee_uuid,
            dns,
        )
        # If no good LDAP account was found, we do not want to synchronize at all
        if best_dn is None:
            logger.info(
                "Aborting synchronization, as no good LDAP account was found",
                dns=dns,
                employee_uuid=employee_uuid,
            )
            return

        # At this point, we have the best possible DN for the user, and their employee UUID
        if dn != best_dn:
            logger.info(
                "Found better DN for employee",
                best_dn=best_dn,
                dns=dns,
                employee_uuid=employee_uuid,
            )
        dn = best_dn
        exit_stack.enter_context(bound_contextvars(dn=dn))

        json_keys = list(self.settings.conversion_mapping.ldap_to_mo.keys())
        json_keys = [
            json_key
            for json_key in json_keys
            if self.settings.conversion_mapping.ldap_to_mo[json_key].import_to_mo
            != "false"
        ]
        logger.info("Import to MO filtered", json_keys=json_keys)

        json_keys = [
            json_key
            for json_key in json_keys
            if await self.perform_import_checks(dn, json_key)
        ]
        logger.info("Import checks executed", json_keys=json_keys)

        template_context = {
            "employee_uuid": str(employee_uuid),
        }

        # The template author should make sure to define objects in order, so
        # dependencies exist before their dependent objects.
        for json_key in json_keys:
            await self.import_single_entity(
                self.get_mapping(json_key), dn, template_context
            )

    @with_exitstack
    async def import_single_object_class(
        self, object_class: str, dn: DN, exit_stack: ExitStack
    ) -> None:
        """Imports a single object class from LDAP into MO."""
        exit_stack.enter_context(bound_contextvars(object_class=object_class, dn=dn))
        logger.info("Importing object class")
        mappings = self.settings.conversion_mapping.ldap_to_mo_any[object_class]
        for mapping in mappings:
            await self.import_single_entity(mapping, dn, template_context={})

    @handle_exclusively_decorator(key=lambda self, mapping, dn, template_context: dn)
    async def import_single_entity(
        self,
        mapping: LDAP2MOMapping,
        dn: DN,
        template_context: dict[str, Any],
    ) -> None:
        if mapping.objectClass == "Custom.JobTitleFromADToMO":  # pragma: no cover
            await sync_JobTitleFromADToMO(
                self.dataloader.moapi, self.ldap_connection, dn
            )
            return

        logger.info("Loading object", mo_class=mapping.as_mo_class(), dn=dn)
        loaded_object = await get_ldap_object(
            ldap_connection=self.ldap_connection,
            dn=dn,
            attributes=set(mapping.ldap_attributes) - {"dn"},
        )
        logger.info(
            "Loaded object",
            mo_class=mapping.as_mo_class(),
            dn=dn,
            loaded_object=loaded_object,
        )

        try:
            converted_object = await self.converter.from_ldap(
                ldap_object=loaded_object,
                mapping=mapping,
                template_context=template_context,
            )
        except SkipObject:
            logger.info("Skipping object", dn=dn)
            return

        logger.info(
            "Converted 'n' objects ",
            n=1,
            dn=dn,
        )

        mo_attributes = set(mapping.get_fields().keys())
        operation = await self.format_converted_object(converted_object, mo_attributes)
        operations = [operation] if operation else []

        if not operations:  # pragma: no cover
            logger.info("No converted objects after formatting", dn=dn)
            return

        logger.info(
            "Importing objects",
            operations=operations,
            dn=dn,
        )
        await self.dataloader.moapi.create_or_edit_mo_objects(operations)
