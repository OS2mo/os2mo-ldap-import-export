# SPDX-FileCopyrightText: Magenta ApS <https://magenta.dk>
# SPDX-License-Identifier: MPL-2.0
import re
import string
from collections.abc import Iterator
from contextlib import suppress
from datetime import datetime
from functools import partial
from itertools import groupby
from typing import Any
from typing import TypeVar
from typing import cast
from uuid import UUID
from uuid import uuid4

import structlog
from fastapi.encoders import jsonable_encoder
from fastramqpi.ramqp.utils import RequeueMessage
from jinja2 import Environment
from jinja2 import StrictUndefined
from jinja2 import TemplateRuntimeError
from jinja2 import UndefinedError
from jinja2.utils import missing
from ldap3 import NO_ATTRIBUTES
from ldap3 import SUBTREE
from ldap3 import Connection
from ldap3.utils.dn import safe_dn
from ldap3.utils.dn import to_dn
from more_itertools import flatten
from more_itertools import ilen
from more_itertools import one
from more_itertools import only
from more_itertools import unzip
from pydantic import parse_obj_as

from mo_ldap_import_export.ldap import get_ldap_object
from mo_ldap_import_export.moapi import MOAPI
from mo_ldap_import_export.moapi import extract_current_or_latest_validity
from mo_ldap_import_export.moapi import flatten_validities
from mo_ldap_import_export.moapi import get_primary_engagement
from mo_ldap_import_export.models import Address
from mo_ldap_import_export.models import Employee
from mo_ldap_import_export.models import Engagement
from mo_ldap_import_export.models import ITUser

from .autogenerated_graphql_client.client import GraphQLClient
from .autogenerated_graphql_client.input_types import AddressFilter
from .autogenerated_graphql_client.input_types import ClassFilter
from .autogenerated_graphql_client.input_types import EmployeeFilter
from .autogenerated_graphql_client.input_types import EngagementFilter
from .autogenerated_graphql_client.input_types import FacetFilter
from .autogenerated_graphql_client.input_types import ITSystemFilter
from .autogenerated_graphql_client.input_types import ITUserFilter
from .autogenerated_graphql_client.input_types import OrganisationUnitFilter
from .autogenerated_graphql_client.input_types import OrgUnitsboundmanagerfilter
from .config import Settings
from .config import UsernameGeneratorConfig
from .dataloaders import DataLoader
from .dataloaders import NoGoodLDAPAccountFound
from .exceptions import NoObjectsReturnedException
from .exceptions import SkipObject
from .exceptions import UUIDNotFoundException
from .ldap import ldap_search
from .types import DN
from .types import EmployeeUUID
from .types import EngagementUUID
from .usernames import generate_person_name
from .utils import MO_TZ
from .utils import ensure_list
from .utils import extract_ou_from_dn
from .utils import get_delete_flag
from .utils import mo_today
from .utils import remove_vowels

logger = structlog.stdlib.get_logger()
T = TypeVar("T")


def filter_mo_datestring(datetime_object):
    """
    Converts a datetime object to a date string which is accepted by MO.

    Notes
    -------
    MO only accepts date objects dated at midnight.
    """
    # TODO: should take timezone-aware datetime_object and convert using MO_TZ.
    if not datetime_object:
        return None
    return datetime_object.strftime("%Y-%m-%dT00:00:00")


def filter_strip_non_digits(input_string):
    if not isinstance(input_string, str):
        return None
    return "".join(c for c in input_string if c in string.digits)


def filter_remove_curly_brackets(text: str) -> str:
    # TODO: Should this remove everything or just a single set?
    return text.replace("{", "").replace("}", "")


def bitwise_and(input: int, bitmask: int) -> int:
    """Bitwise and jinja filter.

    Mostly useful for accessing bits within userAccountControl.

    Args:
        input: The input integer.
        bitmask: The bitmask to filter the input through.

    Returns:
        The bitwise and on input and bitmask.
    """
    return input & bitmask


async def _get_facet_class_uuid(
    graphql_client: GraphQLClient, class_user_key: str, facet_user_key: str
) -> str:
    result = await graphql_client.read_class_uuid_by_facet_and_class_user_key(
        facet_user_key, class_user_key
    )
    exception = UUIDNotFoundException(
        f"class not found, facet_user_key: {facet_user_key} class_user_key: {class_user_key}"
    )
    return str(one(result.objects, too_short=exception).uuid)


get_employee_address_type_uuid = partial(
    _get_facet_class_uuid, facet_user_key="employee_address_type"
)
get_visibility_uuid = partial(_get_facet_class_uuid, facet_user_key="visibility")
get_org_unit_type_uuid = partial(_get_facet_class_uuid, facet_user_key="org_unit_type")
get_engagement_type_uuid = partial(
    _get_facet_class_uuid, facet_user_key="engagement_type"
)
get_primary_type_uuid = partial(_get_facet_class_uuid, facet_user_key="primary_type")


async def get_org_unit_path_string(
    graphql_client: GraphQLClient, org_unit_path_string_separator: str, uuid: str | UUID
) -> str:
    uuid = uuid if isinstance(uuid, UUID) else UUID(uuid)
    result = await graphql_client.read_org_unit_ancestor_names(uuid)
    current = one(result.objects).current
    assert current is not None
    names = [x.name for x in reversed(current.ancestors)] + [current.name]
    assert org_unit_path_string_separator not in names
    return org_unit_path_string_separator.join(names)


# TODO: Clean this up so it always just takes an UUID
async def get_org_unit_name_for_parent(
    graphql_client: GraphQLClient, uuid: UUID | str, layer: int = 0
) -> str | None:
    """Get the name of the ancestor in the n'th layer of the org tree.

    Example:

        Imagine an org-unit tree like the following:
            ```
            └── Kolding Kommune
                └── Sundhed
                    ├── Plejecentre
                    │   ├── Plejecenter Nord
                    │   │   └── Køkken <-- uuid of this provided
                    │   └── Plejecenter Syd
                    │       └── Køkken
                    └── Teknik
            ```

        Calling this function with the uuid above and layer, would return:

        * 0: "Kolding Kommune"
        * 1: "Sundhed"
        * 2: "Plejecentre"
        * 3: "Plejecenter Nord"
        * 4: "Køkken"
        * n: ""

    Args:
        graphql_client: GraphQLClient to fetch org-units from MO with.
        uuid: Organisation Unit UUID of the org-unit to find ancestors of.
        layer: The layer the ancestor to extract is on.

    Returns:
        The name of the ancestor at the n'th layer above the provided org-unit.
        If the layer provided is beyond the depth available None is returned.
    """
    uuid = uuid if isinstance(uuid, UUID) else UUID(uuid)
    result = await graphql_client.read_org_unit_ancestor_names(uuid)
    current = one(result.objects).current
    assert current is not None
    names = [x.name for x in reversed(current.ancestors)] + [current.name]
    with suppress(IndexError):
        return names[layer]
    return None


async def get_job_function_name(graphql_client: GraphQLClient, uuid: UUID) -> str:
    result = await graphql_client.read_class_name_by_class_uuid(uuid)
    job_function = one(result.objects)
    if job_function.current is None:
        raise NoObjectsReturnedException(f"job_function not active, uuid: {uuid}")
    return job_function.current.name


async def get_org_unit_name(graphql_client: GraphQLClient, uuid: UUID) -> str:
    result = await graphql_client.read_org_unit_name(uuid)
    org_unit = one(result.objects)
    if org_unit.current is None:
        raise NoObjectsReturnedException(f"org_unit not active, uuid: {uuid}")
    return org_unit.current.name


async def _create_facet_class(
    moapi: MOAPI, class_user_key: str, facet_user_key: str
) -> UUID:
    """Creates a class under the specified facet in MO.

    Args:
        dataloader: Our dataloader instance
        facet_user_key: User-key of the facet to create the class under.
        class_user_key: The name/user-key to give the class.

    Returns:
        The uuid of the created class
    """
    logger.info("Creating MO class", facet_user_key=facet_user_key, name=class_user_key)
    facet_uuid = await moapi.load_mo_facet_uuid(facet_user_key)
    if facet_uuid is None:
        raise NoObjectsReturnedException(
            f"Could not find facet with user_key = '{facet_user_key}'"
        )
    return await moapi.create_mo_class(
        name=class_user_key, user_key=class_user_key, facet_uuid=facet_uuid
    )


async def _get_or_create_facet_class(
    moapi: MOAPI,
    class_user_key: str,
    facet_user_key: str,
    default: str | None = None,
) -> str:
    if not class_user_key:
        if default is None:
            raise UUIDNotFoundException("Cannot create class without user-key")
        logger.info("class_user_key is empty, using provided default", default=default)
        class_user_key = default
    try:
        return await _get_facet_class_uuid(
            moapi.graphql_client,
            class_user_key=class_user_key,
            facet_user_key=facet_user_key,
        )
    except UUIDNotFoundException:
        uuid = await _create_facet_class(
            moapi,
            class_user_key=class_user_key,
            facet_user_key=facet_user_key,
        )
        return str(uuid)


get_or_create_job_function_uuid = partial(
    _get_or_create_facet_class, facet_user_key="engagement_job_function"
)


async def load_primary_engagement(
    moapi: MOAPI, employee_uuid: UUID
) -> Engagement | None:
    primary_engagement_uuid = await get_primary_engagement(
        moapi.graphql_client, EmployeeUUID(employee_uuid)
    )
    if primary_engagement_uuid is None:
        logger.info(
            "Could not find primary engagement UUID", employee_uuid=employee_uuid
        )
        return None

    fetched_engagement = await moapi.load_mo_engagement(
        primary_engagement_uuid, start=None, end=None
    )
    if fetched_engagement is None:  # pragma: no cover
        logger.error("Unable to load mo engagement", uuid=primary_engagement_uuid)
        raise RequeueMessage("Unable to load mo engagement")
    delete = get_delete_flag(jsonable_encoder(fetched_engagement))
    if delete:
        logger.debug("Primary engagement is terminated", uuid=primary_engagement_uuid)
        return None
    return fetched_engagement


async def load_it_user(
    moapi: MOAPI,
    employee_uuid: UUID,
    itsystem_user_key: str,
    return_terminated: bool = False,
) -> ITUser | None:
    result = await moapi.graphql_client.read_filtered_itusers(
        ITUserFilter(
            employee=EmployeeFilter(uuids=[employee_uuid]),
            itsystem=ITSystemFilter(user_keys=[itsystem_user_key]),
            from_date=None,
            to_date=None,
        )
    )
    if not result.objects:
        logger.info(
            "Could not find it-user",
            employee_uuid=employee_uuid,
            itsystem_user_key=itsystem_user_key,
        )
        return None
    # Flatten all validities to a list
    validities = list(flatten_validities(result))
    validity = extract_current_or_latest_validity(validities)
    if validity is None:  # pragma: no cover
        logger.error(
            "No active validities on it-user",
            employee_uuid=employee_uuid,
            itsystem_user_key=itsystem_user_key,
        )
        raise RequeueMessage("No active validities on it-user")
    fetched_ituser = await moapi.load_mo_it_user(
        validity.uuid, current_objects_only=False
    )
    if fetched_ituser is None:  # pragma: no cover
        logger.error("Unable to load it-user", uuid=validity.uuid)
        raise RequeueMessage("Unable to load it-user")
    # If allowed to return terminated, there is no reason to check for it
    # we simply return whatever we found and use that
    if return_terminated:
        return fetched_ituser
    delete = get_delete_flag(jsonable_encoder(fetched_ituser))
    if delete:
        logger.debug("IT-user is terminated", uuid=validity.uuid)
        return None
    return fetched_ituser


async def create_mo_it_user(
    moapi: MOAPI, employee_uuid: UUID, itsystem_user_key: str, user_key: str
) -> ITUser | None:
    it_system_uuid = UUID(await moapi.get_it_system_uuid(itsystem_user_key))

    # Make a new it-user
    it_user = ITUser(
        user_key=user_key,
        itsystem=it_system_uuid,
        person=employee_uuid,
        validity={"start": mo_today()},
    )
    await moapi.create_ituser(it_user)
    return await load_it_user(moapi, employee_uuid, itsystem_user_key)


async def load_address(
    moapi: MOAPI, employee_uuid: UUID, address_type_user_key: str
) -> Address | None:
    result = await moapi.graphql_client.read_filtered_addresses(
        AddressFilter(
            employee=EmployeeFilter(uuids=[employee_uuid]),
            address_type=ClassFilter(user_keys=[address_type_user_key]),
            from_date=None,
            to_date=None,
        )
    )
    if not result.objects:
        logger.info(
            "Could not find employee address",
            employee_uuid=employee_uuid,
            address_type_user_key=address_type_user_key,
        )
        return None
    # Flatten all validities to a list
    validities = list(flatten_validities(result))
    validity = extract_current_or_latest_validity(validities)
    if validity is None:  # pragma: no cover
        logger.error(
            "No active validities on employee address",
            employee_uuid=employee_uuid,
            address_type_user_key=address_type_user_key,
        )
        raise RequeueMessage("No active validities on employee address")
    fetched_address = await moapi.load_mo_address(
        validity.uuid, current_objects_only=False
    )
    if fetched_address is None:  # pragma: no cover
        logger.error("Unable to load employee address", uuid=validity.uuid)
        raise RequeueMessage("Unable to load employee address")
    delete = get_delete_flag(jsonable_encoder(fetched_address))
    if delete:
        logger.debug("Employee address is terminated", uuid=validity.uuid)
        return None
    return fetched_address


async def load_org_unit_address(
    moapi: MOAPI, employee_uuid: UUID, address_type_user_key: str
) -> Address | None:
    primary_engagement_uuid = await get_primary_engagement(
        moapi.graphql_client, EmployeeUUID(employee_uuid)
    )
    if primary_engagement_uuid is None:
        logger.info(
            "Could not find primary engagement UUID", employee_uuid=employee_uuid
        )
        return None

    result = await moapi.graphql_client.read_filtered_addresses(
        AddressFilter(
            # TODO: Use primary engagement filter here
            org_unit=OrganisationUnitFilter(
                engagement=EngagementFilter(uuids=[primary_engagement_uuid])
            ),
            address_type=ClassFilter(user_keys=[address_type_user_key]),
            from_date=None,
            to_date=None,
        )
    )
    validities = list(flatten(o.validities for o in result.objects))
    validity = extract_current_or_latest_validity(validities)
    if validity is None:
        logger.error(
            "No active validities on org-unit address",
            employee_uuid=employee_uuid,
            address_type_user_key=address_type_user_key,
        )
        return None
    fetched_address = await moapi.load_mo_address(
        validity.uuid, current_objects_only=False
    )
    if fetched_address is None:  # pragma: no cover
        logger.error("Unable to load org-unit address", uuid=validity.uuid)
        raise RequeueMessage("Unable to load org-unit address")
    delete = get_delete_flag(jsonable_encoder(fetched_address))
    if delete:
        logger.debug("Org-unit address is terminated", uuid=validity.uuid)
        return None
    return fetched_address


async def _mo_allows_username(
    moapi: MOAPI,
    username_generator_settings: UsernameGeneratorConfig,
    employee_uuid: EmployeeUUID,
    username: str,
) -> bool:
    # Check if MO allows the username to be used

    # If we are not limiting by mo usernames, the answer is yes, mo allows all
    if not username_generator_settings.disallow_mo_usernames:
        logger.debug("Not configured to check for disallowed MO usernames")
        return True

    # Otherwise, we gotta check if the username is already taken in MO
    #
    # We have to check both past, present and future usernames to ensure no reuse
    # of usernames is ever done. This works as we never actually delete usernames
    # from MO's database, but rather just terminate by putting end-dates on them.
    #
    # We need to block these usernames from being generated, because it is possible
    # that MO generates a user, which is deleted from AD some years later. In that
    # case we should never generate the username of the deleted user.
    # Reference: https://redmine.magenta-aps.dk/issues/57043

    itsystem_user_key = username_generator_settings.existing_usernames_itsystem

    # The username is taken iff there exists atleast one validity in MO where:
    # * The username is set in the user-key
    # * The it-system is our usernames it-system
    result = await moapi.graphql_client.read_filtered_itusers(
        filter=ITUserFilter(
            itsystem=ITSystemFilter(user_keys=[itsystem_user_key]),
            # NOTE: We actually could check a list of candidate usernames here easily
            user_keys=[username],
            # We check all validities; past, present and future
            from_date=None,
            to_date=None,
        )
    )
    logger.debug("Checked for disallowed MO usernames", result=result)
    # None reserves the name, so we can use it
    if not result.objects:
        logger.debug("Username not reserved in MO")
        return True
    # The name is reserved by atleast one user
    # But maybe that user is us, in which case we may be able to reuse it
    if username_generator_settings.reuse_old_usernames:
        # Construct a set of Employee UUIDs which reserve the username
        reserving_employee_uuids = {
            EmployeeUUID(validity.employee_uuid)
            for obj in result.objects
            for validity in obj.validities
            if validity.employee_uuid is not None
        }
        logger.debug(
            "Username reserved in MO, but potentionally allowed for reuse",
            employee_uuid=employee_uuid,
            reserving_employee_uuids=reserving_employee_uuids,
        )
        # We can reuse the username if we are the only employee reserving it
        return {employee_uuid} == reserving_employee_uuids

    # If we get here, the name was reserved, and we could not reuse it
    # Thus MO cannot allow it to be used
    logger.debug("Username reserved in MO")
    return False


async def _ldap_allows_username(
    ldap_connection: Connection, settings: Settings, username: str
) -> bool:
    match settings.ldap_dialect:
        case "Standard":
            # "uid" is the default login field since RFC2798 (inetOrgPerson)
            # (replacing the "userid" term from RFC1274 (COSINE schema))
            # It is the standard LDAP login name field.
            # The Microsoft Active Directory equivalent is sAMAccountName
            search_filters = [f"(uid={username})"]
        case "AD":  # pragma: no cover
            search_filters = [
                f"(sAMAccountName={username})",
                f"(userPrincipalName={username}@*)",
            ]
        case _:  # pragma: no cover
            raise AssertionError("Unknown LDAP dialect")

    for search_filter in search_filters:
        response, result = await ldap_search(
            ldap_connection,
            search_base=settings.ldap_search_base,
            search_filter=search_filter,
            attributes=NO_ATTRIBUTES,
            search_scope=SUBTREE,
            size_limit=1,
        )
        if result["type"] != "searchResDone":  # pragma: no cover
            logger.warning(
                "LDAP connection search returned unexpected result type",
                response=response,
                result=result,
            )
            raise ValueError("Unexpected search result type")
        if result["description"] != "success":  # pragma: no cover
            logger.warning(
                "LDAP connection did not search sucessfully",
                response=response,
                result=result,
            )
            raise ValueError("Search failed")
        # If we got any results, we have found a conflict
        if response != []:
            return False

    return True


def _create_from_combi(name_parts: list[str], combi: str) -> str | None:
    """Create a username from a name and a combination.

    Args:
        name_parts: An array of names; given_name, middlenames, surname.
        combi: Combination to create a username from. For example "F123LX".

    Raises:
        AssertionError: If an invalid character is provided as combi.

    Returns:
        A username generated according to the combination.
        Note that this username may still contain 'X' characters, which need
        to be replaced with a number.
    """

    def char2namepart(combi_char: str) -> str:
        """Convert combi character to corresponding name part.

        Args:
            combi_char: The character to lookup (One of "F", "L", [1-9])

        Raises:
            ValueError: If the captured name_parts has less than 2 entries.
            IndexError: If an integer higher than the number of middlenames is used.
            AssertionError: If an invalid character is provided as combi_char.

        Returns:
            The name part corresponding to the combi character.
        """
        assert combi_char in {"F", "L"} | {str(x) for x in range(1, 10)}

        given_name, *middlenames, surname = name_parts
        match combi_char:
            case "F":
                return given_name
            case "L":
                return surname
            case x:
                index = int(x) - 1
                return middlenames[index]

    def group2string(combi_char: str, count: int) -> str:
        """Construct a username substring from a group (combi_char + count).

        Args:
            combi_char: The character to lookup (One of "X", "F", "L", [1-9])
            count: The number of characters to extract from the combi_char source.

        Raises:
            ValueError: If a referenced name_part does not have enough characters.
            ValueError: If the captured name_parts has less than 2 entries.
            IndexError: If an integer higher than the number of middlenames is used.
            AssertionError: If an invalid character is provided as combi_char.

        Returns:
            The constructed username substring.
        """
        if combi_char == "X":
            return "X" * count
        name_part = char2namepart(combi_char).lower()
        # Sanity check that the name is long enough
        # Without this check we risk making too short usernames
        if count > len(name_part):
            raise ValueError("Name part too short")
        return name_part[:count]

    # Split code into groups on changes
    # For example "FF1LL" returns [("F",2), ("1",1), ("L",2)]
    groups = [(key, ilen(group)) for key, group in groupby(combi)]

    with suppress(IndexError, ValueError):
        username_parts = [group2string(char, count) for (char, count) in groups]
        return "".join(username_parts)
    return None


def _name_fixer(
    char_replacement: dict[str, str], do_remove_vowels: bool, name_parts: list[str]
) -> list[str]:
    """Cleanup a structured name to remove non-ascii characters.

    Context:
        char_replacement:
            Dictionary from one set of characters to their replacements.

    Args:
        name_parts: An array of names; given_name, middlenames, surname.

    Returns:
        `name_parts` where non-ascii characters have been replaced
        according to the char_replacement map, or if unmatched, removed.
    """

    def fix_name(name: str) -> str:
        # Replace according to replacement list
        for char, replacement in char_replacement.items():
            name = name.replace(char, replacement)
        # Remove all remaining characters outside a-z
        return re.sub(r"[^a-z]+", "", name.lower())

    def eliminate_vowels_from_surnames(name_parts: list[str]) -> list[str]:
        # Remove vowels from all but first name
        # Reference: https://redmine.magenta-aps.dk/issues/56080
        first_name, *lastnames = name_parts
        return [first_name] + [remove_vowels(n) for n in lastnames]

    name_parts = [fix_name(x) for x in name_parts]
    if do_remove_vowels:
        name_parts = eliminate_vowels_from_surnames(name_parts)
    return name_parts


async def _create_username(
    settings: Settings,
    ldap_connection: Connection,
    moapi: MOAPI,
    employee_uuid: EmployeeUUID,
    name: list[str],
) -> str:
    """
    Create a new username in accordance with the rules specified in the json file.
    The username will be the highest quality available and the value will be
    added to list of used names, so consequtive calles with the same name
    will keep returning new names until the algorithm runs out of options
    and a RuntimeException is raised.

    :param name: Name of the user given as a list with at least two elements.
    :return: New username generated.

    Inspired by ad_integration/usernames.py
    """
    username_generator_settings = settings.conversion_mapping.username_generator
    forbidden_usernames = username_generator_settings.forbidden_usernames
    logger.debug("Found forbidden usernames", count=len(forbidden_usernames))

    def permutations(username: str) -> Iterator[str]:
        # The permutation is a number inside the username, it is normally only used in
        # case a username is already occupied. It can be specified using 'X' in the
        # username template.
        #
        # The first attempted permutation should be '2':
        # For example; If 'cvt' is occupied, a username 'cvt2' will be generated.
        #
        # The last attempted permutation is '9' - because we would like to limit the
        # permutation counter to a single digit.
        if "X" in username:
            for permutation_counter in range(2, 10):
                yield username.replace("X", str(permutation_counter))
        else:
            yield username

    def forbidden(username: str) -> bool:
        # Check if core username is legal
        return username.replace("X", "") in forbidden_usernames

    # Cleanup names
    clean_name = _name_fixer(
        username_generator_settings.char_replacement,
        username_generator_settings.remove_vowels,
        name,
    )
    logger.debug(
        "Cleaned name for username generation", name=name, clean_name=clean_name
    )

    combinations = username_generator_settings.combinations_to_try
    for combination in combinations:
        # Generate usernames from clean_name and combination
        username = _create_from_combi(clean_name, combination)
        username_logger = logger.bind(combination=combination, username=username)
        username_logger.debug("Username candidate generated")

        if username is None:
            username_logger.debug("Rejecting empty username")
            continue

        if forbidden(username):
            username_logger.debug("Rejecting forbidden username")
            continue

        p_usernames = permutations(username)
        for p_username in p_usernames:
            permutation_logger = username_logger.bind(permutation=p_username)
            permutation_logger.debug("Username permutation generated")

            if not await _ldap_allows_username(ldap_connection, settings, p_username):
                permutation_logger.debug(
                    "Rejecting username candidate due to existing LDAP usage"
                )
                continue

            if not await _mo_allows_username(
                moapi, username_generator_settings, employee_uuid, p_username
            ):
                permutation_logger.debug(
                    "Rejecting username candidate due to disallowed MO usernames"
                )
                continue

            return p_username

    # TODO: Return a more specific exception type
    raise RuntimeError("Failed to create user name.")


async def generate_username_func(
    settings: Settings, ldap_connection: Connection, moapi: MOAPI, employee: Employee
) -> str:
    name = generate_person_name(employee)
    username = await _create_username(
        settings, ldap_connection, moapi, EmployeeUUID(employee.uuid), name
    )
    logger.info("Generated username based on name", name=name, username=username)
    return username


async def generate_username(
    dataloader: DataLoader,
    employee_uuid: UUID,
) -> str:
    employee = await dataloader.moapi.load_mo_employee(employee_uuid)
    if employee is None:  # pragma: no cover
        raise NoObjectsReturnedException(f"Unable to lookup employee: {employee_uuid}")
    return cast(
        str,
        await generate_username_func(
            dataloader.settings,
            dataloader.ldapapi.ldap_connection,
            dataloader.moapi,
            employee,
        ),
    )


async def fetch_current_common_name(
    ldap_connection: Connection, dn: DN | None
) -> str | None:
    if dn is None:
        return None
    ldap_common_name = None
    with suppress(NoObjectsReturnedException):
        ldap_object = await get_ldap_object(ldap_connection, dn, {"cn"})
        ldap_common_name = getattr(ldap_object, "cn", None)
    # It is an invariant that common name is always be set
    assert ldap_common_name is not None
    # This is a list on OpenLDAP, but not on AD
    # We use ensure_list to ensure that AD is handled like Standard LDAP
    current_common_name = one(ensure_list(ldap_common_name))
    # IT is an invariant that common name is a string
    assert current_common_name is not None
    assert isinstance(current_common_name, str)
    return current_common_name


async def generate_common_name(
    dataloader: DataLoader,
    employee_uuid: UUID,
    dn: DN | None,
) -> str:
    employee = await dataloader.moapi.load_mo_employee(employee_uuid)
    if employee is None:  # pragma: no cover
        raise NoObjectsReturnedException(f"Unable to lookup employee: {employee_uuid}")
    # Fetch the current common name (if any)
    current_common_name = await fetch_current_common_name(
        dataloader.ldapapi.ldap_connection, dn
    )
    return cast(
        str,
        await dataloader.username_generator.generate_common_name(
            employee, current_common_name
        ),
    )


async def get_person_uuid(
    graphql_client: GraphQLClient, filter: dict[str, Any]
) -> UUID | None:
    person_filter = parse_obj_as(EmployeeFilter, filter)
    result = await graphql_client.read_person_uuid(person_filter)
    obj = only(result.objects)
    return obj.uuid if obj else None


async def get_address_uuid(
    graphql_client: GraphQLClient, filter: dict[str, Any]
) -> UUID | None:
    address_filter = parse_obj_as(AddressFilter, filter)
    result = await graphql_client.read_address_uuid(address_filter)
    obj = only(result.objects)
    return obj.uuid if obj else None


async def get_ituser_uuid(
    graphql_client: GraphQLClient, filter: dict[str, Any]
) -> UUID | None:
    ituser_filter = parse_obj_as(ITUserFilter, filter)
    result = await graphql_client.read_ituser_uuid(ituser_filter)
    obj = only(result.objects)
    return obj.uuid if obj else None


async def get_itsystem_uuid(
    graphql_client: GraphQLClient, filter: dict[str, Any]
) -> UUID | None:
    itsystem_filter = parse_obj_as(ITSystemFilter, filter)
    result = await graphql_client.read_itsystem_uuid(itsystem_filter)
    obj = only(result.objects)
    return obj.uuid if obj else None


async def get_class_uuid(
    graphql_client: GraphQLClient, filter: dict[str, Any]
) -> UUID | None:
    class_filter = parse_obj_as(ClassFilter, filter)
    result = await graphql_client.read_class_uuid(class_filter)
    obj = only(result.objects)
    return obj.uuid if obj else None


async def get_facet_uuid(
    graphql_client: GraphQLClient, filter: dict[str, Any]
) -> UUID | None:
    facet_filter = parse_obj_as(FacetFilter, filter)
    result = await graphql_client.read_facet_uuid(facet_filter)
    obj = only(result.objects)
    return obj.uuid if obj else None


async def get_engagement_uuid(
    graphql_client: GraphQLClient, filter: dict[str, Any]
) -> UUID | None:
    engagement_filter = parse_obj_as(EngagementFilter, filter)
    result = await graphql_client.read_engagement_uuid(engagement_filter)
    obj = only(result.objects)
    return obj.uuid if obj else None


async def get_org_unit_uuid(
    graphql_client: GraphQLClient, filter: dict[str, Any]
) -> UUID | None:
    org_unit_filter = parse_obj_as(OrganisationUnitFilter, filter)
    result = await graphql_client.read_org_unit_uuid(org_unit_filter)
    obj = only(result.objects)
    return obj.uuid if obj else None


async def get_employment_interval(
    graphql_client: GraphQLClient, employee_uuid: UUID
) -> tuple[datetime | None, datetime | None]:
    result = await graphql_client.read_engagement_enddate(employee_uuid)
    if not result.objects:
        return None, None

    tzmin = datetime.min.replace(tzinfo=MO_TZ)
    tzmax = datetime.max.replace(tzinfo=MO_TZ)

    start_dates, end_dates = unzip(
        (validity.validity.from_ or tzmin, validity.validity.to or tzmax)
        for engagement in result.objects
        for validity in engagement.validities
    )
    startdate = min(start_dates)
    enddate = max(end_dates)
    return startdate, enddate


async def get_manager_person_uuid(
    graphql_client: GraphQLClient,
    engagement_uuid: EngagementUUID,
    filter: dict[str, Any] | None = None,
) -> UUID | None:
    manager_filter = None
    if filter:
        manager_filter = parse_obj_as(OrgUnitsboundmanagerfilter, filter)
    result = await graphql_client.read_engagement_manager(
        engagement_uuid, manager_filter
    )

    obj = only(result.objects)
    if obj is None:
        logger.debug("Invalid engagement", engagement_uuid=engagement_uuid)
        return None

    current = obj.current
    # Our lookup is specifically for current engagements
    assert current is not None

    # NOTE: We assume that there is at most one manager in managers, as any others
    #       should have have been filtered using the manager filter.
    manager = only(current.managers)
    if manager is None:
        logger.debug(
            "No manager relation found",
            engagement_uuid=engagement_uuid,
            manager_filter=filter,
        )
        return None

    # NOTE: manager.person may be null if we hit a vacant manager position
    #       The caller can avoid this, by setting `employee: null` on the manager filter.
    if manager.person is None:
        logger.debug(
            "Vacant manager found",
            engagement_uuid=engagement_uuid,
            manager_filter=filter,
        )
        return None

    manager_validity = one(manager.person)
    return manager_validity.uuid


async def get_person_dn(dataloader: DataLoader, uuid: EmployeeUUID) -> DN | None:
    with suppress(NoGoodLDAPAccountFound):
        return await dataloader._find_best_dn(uuid)
    return None


def skip_if_none(obj: T | None) -> T:
    if obj is None:
        raise SkipObject("Skipping: Object is None")
    return obj


def requeue_if_none(obj: T | None) -> T:
    if obj is None:
        raise RequeueMessage("Requeueing: Object is None")
    return obj


def parent_dn(dn: DN) -> DN:
    dn_parts = to_dn(dn)
    parent_dn_parts = dn_parts[1:]
    return cast(DN, safe_dn(parent_dn_parts))


def dn_has_ou(dn: DN) -> bool:
    return bool(extract_ou_from_dn(dn))


def construct_globals_dict(
    settings: Settings, dataloader: DataLoader
) -> dict[str, Any]:
    moapi = dataloader.moapi
    graphql_client = moapi.graphql_client
    return {
        "get_employee_address_type_uuid": partial(
            get_employee_address_type_uuid, graphql_client
        ),
        "get_it_system_uuid": partial(moapi.get_it_system_uuid),
        "get_visibility_uuid": partial(get_visibility_uuid, graphql_client),
        "get_org_unit_type_uuid": partial(get_org_unit_type_uuid, graphql_client),
        "get_org_unit_path_string": partial(
            get_org_unit_path_string,
            graphql_client,
            settings.org_unit_path_string_separator,
        ),
        "get_org_unit_name_for_parent": partial(
            get_org_unit_name_for_parent, graphql_client
        ),
        "get_job_function_name": partial(get_job_function_name, graphql_client),
        "get_org_unit_name": partial(get_org_unit_name, graphql_client),
        "get_or_create_job_function_uuid": partial(
            get_or_create_job_function_uuid, moapi
        ),
        # These names are intentionally bad, but consistent with the old code names
        # TODO: Rename these functions once the old template system is gone
        "load_mo_employee": moapi.load_mo_employee,
        "load_mo_primary_engagement": partial(load_primary_engagement, moapi),
        "load_mo_it_user": partial(load_it_user, moapi),
        "load_mo_address": partial(load_address, moapi),
        "load_mo_org_unit_address": partial(load_org_unit_address, moapi),
        "create_mo_it_user": partial(create_mo_it_user, moapi),
        "generate_username": partial(generate_username, dataloader),
        "generate_common_name": partial(generate_common_name, dataloader),
        "get_person_uuid": partial(get_person_uuid, graphql_client),
        "get_address_uuid": partial(get_address_uuid, graphql_client),
        "get_ituser_uuid": partial(get_ituser_uuid, graphql_client),
        "get_itsystem_uuid": partial(get_itsystem_uuid, graphql_client),
        "get_class_uuid": partial(get_class_uuid, graphql_client),
        "get_facet_uuid": partial(get_facet_uuid, graphql_client),
        "get_engagement_uuid": partial(get_engagement_uuid, graphql_client),
        "get_org_unit_uuid": partial(get_org_unit_uuid, graphql_client),
        "get_employment_interval": partial(get_employment_interval, graphql_client),
        "get_manager_person_uuid": partial(get_manager_person_uuid, graphql_client),
        "get_person_dn": partial(get_person_dn, dataloader),
        "dn_to_uuid": dataloader.ldapapi.get_ldap_unique_ldap_uuid,
        "get_engagement_type_uuid": partial(get_engagement_type_uuid, graphql_client),
        "get_primary_type_uuid": partial(get_primary_type_uuid, graphql_client),
        "get_ldap_object": partial(get_ldap_object, dataloader.ldapapi.ldap_connection),
    }


class NeverUndefined(StrictUndefined):
    """https://github.com/pallets/jinja/issues/1923."""

    def __init__(
        self,
        hint: str | None = None,
        obj: Any = missing,
        name: str | None = None,
        exc: type[TemplateRuntimeError] = UndefinedError,
    ) -> None:
        raise Exception(
            f"Undefined variable '{name}' with object {obj} (hint: {hint})"
        ) from exc


def construct_default_environment() -> Environment:
    # We intentionally use 'StrictUndefined' here so undefined accesses yield exceptions
    # instead of silently coercing to falsy values as is the case with 'Undefined'
    # See: https://jinja.palletsprojects.com/en/3.1.x/api/#undefined-types
    # For more details.
    environment = Environment(undefined=NeverUndefined, enable_async=True)

    environment.filters["bitwise_and"] = bitwise_and
    environment.filters["mo_datestring"] = filter_mo_datestring
    environment.filters["strip_non_digits"] = filter_strip_non_digits
    environment.filters["remove_curly_brackets"] = filter_remove_curly_brackets

    environment.globals["now"] = datetime.utcnow  # TODO: timezone-aware datetime
    environment.globals["skip_if_none"] = skip_if_none
    environment.globals["requeue_if_none"] = requeue_if_none
    environment.globals["uuid4"] = uuid4
    environment.globals["parent_dn"] = parent_dn
    environment.globals["dn_has_ou"] = dn_has_ou

    return environment


def construct_environment(settings: Settings, dataloader: DataLoader) -> Environment:
    environment = construct_default_environment()
    environment.globals.update(construct_globals_dict(settings, dataloader))
    return environment
