# SPDX-FileCopyrightText: Magenta ApS <https://magenta.dk>
# SPDX-License-Identifier: MPL-2.0
import math
from datetime import datetime
from datetime import time
from typing import Annotated
from zoneinfo import ZoneInfo

import structlog
from fastapi import APIRouter
from fastapi import Depends
from fastapi import HTTPException
from fastramqpi.events import Event
from fastramqpi.ramqp.depends import get_payload_as_type
from more_itertools import only

from . import depends
from .autogenerated_graphql_client import ListenerFilter
from .autogenerated_graphql_client import NamespaceFilter
from .depends import DataLoader
from .depends import Settings
from .depends import SyncTool
from .exceptions import AcknowledgeException
from .types import LDAPUUID

logger = structlog.stdlib.get_logger()


ldap2mo_router = APIRouter(prefix="/ldap2mo")

PayloadUUID = Annotated[LDAPUUID, Depends(get_payload_as_type(LDAPUUID))]


async def delay_ldap(settings: Settings) -> None:
    if not settings.disallow_ldap_processing_between_7_45_and_8_45:
        return

    tz = ZoneInfo("Europe/Copenhagen")
    now = datetime.now(tz=tz)

    start = time(7, 45)
    end = time(8, 45)

    disallowed = start <= now.time() <= end
    if not disallowed:
        return

    end_dt = datetime.combine(now.date(), end, tzinfo=tz)
    next_opening_seconds = (end_dt - now).total_seconds()

    raise HTTPException(
        status_code=503,
        detail="Inside of disallowed interval",
        headers={"Retry-After": str(math.ceil(next_opening_seconds))},
    )


@ldap2mo_router.post("/uuid", dependencies=[Depends(delay_ldap)])
async def http_process_uuid(
    settings: Settings,
    sync_tool: SyncTool,
    dataloader: DataLoader,
    event: Event[LDAPUUID],
) -> None:
    uuid = event.subject
    logger.info("Received LDAP event", uuid=uuid)

    if uuid in settings.ldap_uuids_to_ignore:
        logger.warning("LDAP event ignored due to ignore-list", ldap_uuid=uuid)
        return

    attributes_to_fetch = {"objectClass", settings.ldap_unique_id_field}
    if settings.ldap_cpr_attribute:
        attributes_to_fetch.add(settings.ldap_cpr_attribute)

    if settings.conversion_mapping.ldap_to_mo:
        attributes_to_fetch |= {
            attr
            for mapping in settings.conversion_mapping.ldap_to_mo.values()
            for attr in mapping.ldap_attributes
        }

    if settings.discriminator_fields:  # pragma: no cover
        attributes_to_fetch.update(settings.discriminator_fields)

    attributes_to_fetch |= {
        attr
        for mappings in settings.conversion_mapping.ldap_to_mo_any.values()
        for mapping in mappings
        for attr in mapping.ldap_attributes
    }

    ldap_object = await dataloader.ldapapi.get_object_by_uuid(
        uuid, attributes=attributes_to_fetch
    )
    if ldap_object is None:
        logger.error("LDAP UUID could not be found", uuid=uuid)
        raise AcknowledgeException("LDAP UUID could not be found")

    # Ignore changes to non-employee objects
    assert hasattr(ldap_object, "objectClass")
    ldap_object_classes = ldap_object.objectClass

    # TODO: Eliminate this branch by handling employees as any other object
    employee_object_class = settings.ldap_object_class
    if employee_object_class in ldap_object_classes:
        logger.info("Handling employee", ldap_object_classes=ldap_object_classes)
        await sync_tool.import_single_user(ldap_object)

    for object_class in settings.conversion_mapping.ldap_to_mo_any:
        if object_class in ldap_object_classes:
            logger.info(
                "Handling LDAP event",
                object_class=object_class,
                ldap_object_classes=ldap_object_classes,
            )
            await sync_tool.import_single_object_class(object_class, ldap_object)


@ldap2mo_router.post("/reconcile", dependencies=[Depends(delay_ldap)])
async def http_reconcile_uuid(
    settings: Settings,
    dataloader: DataLoader,
    graphql_client: depends.GraphQLClient,
    event: Event[LDAPUUID],
) -> None:
    uuid = event.subject
    logger.info("Received LDAP event (Reconcile)", uuid=uuid)

    if uuid in settings.ldap_uuids_to_ignore:
        logger.warning("LDAP event ignored due to ignore-list", ldap_uuid=uuid)
        return

    attributes_to_fetch = {settings.ldap_unique_id_field}
    if settings.ldap_cpr_attribute:
        attributes_to_fetch.add(settings.ldap_cpr_attribute)

    ldap_object = await dataloader.ldapapi.get_object_by_uuid(
        uuid, attributes=attributes_to_fetch
    )
    if ldap_object is None:
        logger.error("LDAP UUID could not be found", uuid=uuid)
        raise AcknowledgeException("LDAP UUID could not be found")

    person_uuid = await dataloader.find_mo_employee_uuid(ldap_object)
    if person_uuid is None:
        return
    # We handle reconciliation by seeding events into the normal processing queue
    me = await graphql_client.who_am_i()
    listeners = await graphql_client.read_event_listeners(
        filter=ListenerFilter(
            namespaces=NamespaceFilter(names=["mo"]),
            owners=[me.actor.uuid],
            user_keys=[f"{settings.event_namespace}_internal_process_person"],
        ),
    )
    listener = only(listeners.objects)
    if listener is None:
        # Not listening to changes in MO
        return
    await graphql_client.person_refresh(uuids=[person_uuid], listener=listener.uuid)
