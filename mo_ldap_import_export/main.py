# SPDX-FileCopyrightText: Magenta ApS <https://magenta.dk>
# SPDX-License-Identifier: MPL-2.0
"""Event handling."""

import asyncio
import json
from collections.abc import AsyncIterator
from collections.abc import Callable
from contextlib import AsyncExitStack
from contextlib import asynccontextmanager
from contextlib import suppress
from typing import Annotated
from typing import Any
from uuid import UUID

import structlog
from fastapi import APIRouter
from fastapi import Body
from fastapi import Depends
from fastapi import FastAPI
from fastapi import HTTPException
from fastramqpi.events import Event
from fastramqpi.events import GraphQLEvents
from fastramqpi.events import Listener
from fastramqpi.main import FastRAMQPI
from fastramqpi.ramqp import AMQPSystem
from fastramqpi.ramqp.depends import handle_exclusively_decorator
from fastramqpi.ramqp.depends import rate_limit
from fastramqpi.ramqp.mo import MOAMQPSystem
from fastramqpi.ramqp.mo import MORouter
from fastramqpi.ramqp.mo import PayloadUUID
from fastramqpi.ramqp.utils import RequeueMessage
from ldap3 import Connection
from ldap3.core.exceptions import LDAPNoSuchObjectResult
from ldap3.core.exceptions import LDAPObjectClassViolationResult
from ldap3.core.exceptions import LDAPUnwillingToPerformResult
from pydantic import BaseModel
from pydantic import Extra
from pydantic import ValidationError
from pydantic import parse_raw_as
from pydantic import validator
from structlog.contextvars import bound_contextvars

from mo_ldap_import_export.ldapapi import LDAPAPI
from mo_ldap_import_export.moapi import MOAPI
from mo_ldap_import_export.types import EmployeeUUID
from mo_ldap_import_export.utils import ensure_list

from . import depends
from .autogenerated_graphql_client import GraphQLClient
from .config import SLEEP_ON_ERROR
from .config import Settings
from .converters import LdapConverter
from .customer_specific_checks import ExportChecks
from .customer_specific_checks import ImportChecks
from .database import Base
from .dataloaders import DataLoader
from .exceptions import NoObjectsReturnedException
from .exceptions import amqp_reject_on_failure
from .exceptions import http_reject_on_failure
from .import_export import SyncTool
from .ldap import check_ou_in_list_of_ous
from .ldap import configure_ldap_connection
from .ldap import ldap_healthcheck
from .ldap_amqp import configure_ldap_amqpsystem
from .ldap_amqp import ldap2mo_router
from .ldap_event_generator import LDAPEventGenerator
from .ldap_event_generator import ldap_event_router
from .routes import construct_router
from .usernames import UserNameGenerator

GRAPHQL_VERSION = 25

logger = structlog.stdlib.get_logger()

amqp_router = MORouter()
mo2ldap_router = APIRouter(prefix="/mo2ldap")


@mo2ldap_router.post("/address")
@http_reject_on_failure
async def http_process_address(
    object_uuid: Annotated[UUID, Body()],
    graphql_client: depends.GraphQLClient,
    amqpsystem: depends.AMQPSystem,
) -> None:
    await handle_address(object_uuid, graphql_client, amqpsystem)


@amqp_router.register("address")
@amqp_reject_on_failure
async def process_address(
    object_uuid: PayloadUUID,
    graphql_client: depends.GraphQLClient,
    amqpsystem: depends.AMQPSystem,
) -> None:
    await handle_address(object_uuid, graphql_client, amqpsystem)


async def handle_address(
    object_uuid: UUID,
    graphql_client: depends.GraphQLClient,
    amqpsystem: depends.AMQPSystem,
) -> None:
    logger.info("Registered change in an address", object_uuid=object_uuid)
    result = await graphql_client.read_address_relation_uuids(object_uuid)
    person_uuids = {
        validity.employee_uuid
        for obj in result.objects
        for validity in obj.validities
        if validity.employee_uuid is not None
    }
    org_unit_uuids = {
        validity.org_unit_uuid
        for obj in result.objects
        for validity in obj.validities
        if validity.org_unit_uuid is not None
    }

    if person_uuids:
        # TODO: Add support for refreshing persons with a certain address directly
        await graphql_client.person_refresh(
            list(person_uuids), amqpsystem.exchange_name
        )
    if org_unit_uuids:
        await graphql_client.org_unit_refresh(
            list(org_unit_uuids), amqpsystem.exchange_name
        )


@mo2ldap_router.post("/engagement")
@http_reject_on_failure
async def http_process_engagement(
    object_uuid: Annotated[UUID, Body()],
    graphql_client: depends.GraphQLClient,
    amqpsystem: depends.AMQPSystem,
) -> None:
    await handle_engagement(object_uuid, graphql_client, amqpsystem)


@amqp_router.register("engagement")
@amqp_reject_on_failure
async def process_engagement(
    object_uuid: PayloadUUID,
    graphql_client: depends.GraphQLClient,
    amqpsystem: depends.AMQPSystem,
) -> None:
    await handle_engagement(object_uuid, graphql_client, amqpsystem)


async def handle_engagement(
    object_uuid: UUID,
    graphql_client: depends.GraphQLClient,
    amqpsystem: depends.AMQPSystem,
) -> None:
    logger.info("Registered change in an engagement", object_uuid=object_uuid)
    result = await graphql_client.read_engagement_employee_uuid(object_uuid)
    person_uuids = {
        validity.employee_uuid for obj in result.objects for validity in obj.validities
    }
    if not person_uuids:
        logger.warning("Unable to lookup Engagement", uuid=object_uuid)
        return
    # TODO: Add support for refreshing persons with a certain engagement directly
    await graphql_client.person_refresh(list(person_uuids), amqpsystem.exchange_name)


@mo2ldap_router.post("/ituser")
@http_reject_on_failure
async def http_process_ituser(
    object_uuid: Annotated[UUID, Body()],
    graphql_client: depends.GraphQLClient,
    amqpsystem: depends.AMQPSystem,
) -> None:
    await handle_ituser(object_uuid, graphql_client, amqpsystem)


@amqp_router.register("ituser")
@amqp_reject_on_failure
async def process_ituser(
    object_uuid: PayloadUUID,
    graphql_client: depends.GraphQLClient,
    amqpsystem: depends.AMQPSystem,
) -> None:
    await handle_ituser(object_uuid, graphql_client, amqpsystem)


async def handle_ituser(
    object_uuid: UUID,
    graphql_client: depends.GraphQLClient,
    amqpsystem: depends.AMQPSystem,
) -> None:
    logger.info("Registered change in an ituser", object_uuid=object_uuid)
    result = await graphql_client.read_ituser_relation_uuids(object_uuid)
    person_uuids = {
        validity.employee_uuid
        for obj in result.objects
        for validity in obj.validities
        if validity.employee_uuid is not None
    }
    org_unit_uuids = {
        validity.org_unit_uuid
        for obj in result.objects
        for validity in obj.validities
        if validity.org_unit_uuid is not None
    }
    if person_uuids:
        # TODO: Add support for refreshing persons with a certain address directly
        await graphql_client.person_refresh(
            list(person_uuids), amqpsystem.exchange_name
        )
    if org_unit_uuids:
        await graphql_client.org_unit_refresh(
            list(org_unit_uuids), amqpsystem.exchange_name
        )


@mo2ldap_router.post("/person")
@handle_exclusively_decorator(key=lambda object_uuid, *_, **__: object_uuid)
@http_reject_on_failure
async def http_process_person(
    object_uuid: Annotated[EmployeeUUID, Body()],
    settings: depends.Settings,
    sync_tool: depends.SyncTool,
) -> dict[str, list[Any]]:
    return await handle_person(object_uuid, settings, sync_tool)


@amqp_router.register("person")
@handle_exclusively_decorator(key=lambda object_uuid, *_, **__: object_uuid)
async def process_person(
    object_uuid: PayloadUUID,
    settings: depends.Settings,
    sync_tool: depends.SyncTool,
    amqpsystem: depends.AMQPSystem,
) -> None:
    try:
        await amqp_reject_on_failure(handle_person)(
            EmployeeUUID(object_uuid), settings, sync_tool
        )
    except RequeueMessage:  # pragma: no cover
        # NOTE: This is a hack to cycle messages because quorum queues do not work
        # NOTE: We intentionally publish to this specific queue instead of the exchange,
        #       as we may otherwise trigger both this handler AND the reconcile handler
        #       and if both handlers end up failing, we have an exponential growth in
        #       the number of unhandled messages.
        await asyncio.sleep(SLEEP_ON_ERROR)
        queue_prefix = settings.fastramqpi.amqp.queue_prefix
        queue_name = f"{queue_prefix}_process_person"
        await amqpsystem.publish_message_to_queue(queue_name, object_uuid)  # type: ignore


async def handle_person(
    object_uuid: EmployeeUUID, settings: Settings, sync_tool: SyncTool
) -> dict[str, list[Any]]:
    logger.info("Registered change in a person", object_uuid=object_uuid)
    if object_uuid in settings.mo_uuids_to_ignore:
        logger.warning("MO event ignored due to ignore-list", uuid=object_uuid)
        return {}

    return await sync_tool.listen_to_changes_in_employees(object_uuid)


@mo2ldap_router.post("/reconcile")
@http_reject_on_failure
async def http_reconcile_person(
    object_uuid: Annotated[UUID, Body()],
    settings: depends.Settings,
    dataloader: depends.DataLoader,
    ldap_amqpsystem: depends.LDAPAMQPSystem,
) -> None:
    await handle_person_reconciliation(
        object_uuid, settings, dataloader, ldap_amqpsystem
    )


@amqp_router.register("person")
@handle_exclusively_decorator(key=lambda object_uuid, *_, **__: object_uuid)
async def reconcile_person(
    object_uuid: PayloadUUID,
    settings: depends.Settings,
    dataloader: depends.DataLoader,
    amqpsystem: depends.AMQPSystem,
    ldap_amqpsystem: depends.LDAPAMQPSystem,
) -> None:
    try:
        await handle_person_reconciliation(
            object_uuid, settings, dataloader, ldap_amqpsystem
        )
    except RequeueMessage:  # pragma: no cover
        # NOTE: This is a hack to cycle messages because quorum queues do not work
        # NOTE: We intentionally publish to this specific queue instead of the exchange,
        #       as we may otherwise trigger both this handler AND the reconcile handler
        #       and if both handlers end up failing, we have an exponential growth in
        #       the number of unhandled messages.
        await asyncio.sleep(SLEEP_ON_ERROR)
        queue_prefix = settings.fastramqpi.amqp.queue_prefix
        queue_name = f"{queue_prefix}_reconcile_person"
        await amqpsystem.publish_message_to_queue(queue_name, object_uuid)  # type: ignore


async def handle_person_reconciliation(
    object_uuid: PayloadUUID,
    settings: depends.Settings,
    dataloader: depends.DataLoader,
    ldap_amqpsystem: AMQPSystem,
) -> None:
    logger.info("Registered change in a person (Reconcile)", object_uuid=object_uuid)
    if object_uuid in settings.mo_uuids_to_ignore:
        logger.warning("MO event ignored due to ignore-list")
        return

    dns = await dataloader.find_mo_employee_dn(object_uuid)
    ldap_uuids = set()
    for dn in dns:
        with suppress(NoObjectsReturnedException):
            ldap_uuids.add(await dataloader.ldapapi.get_ldap_unique_ldap_uuid(dn))

    for ldap_uuid in ldap_uuids:
        # We handle reconciliation by seeding events into the normal processing queue
        queue_prefix = settings.ldap_amqp.queue_prefix
        queue_name = f"{queue_prefix}_process_uuid"
        await ldap_amqpsystem.publish_message_to_queue(queue_name, ldap_uuid)


@mo2ldap_router.post("/org_unit")
@http_reject_on_failure
async def http_process_org_unit(
    object_uuid: Annotated[UUID, Body()],
    graphql_client: depends.GraphQLClient,
    amqpsystem: depends.AMQPSystem,
) -> None:
    await handle_org_unit(object_uuid, graphql_client, amqpsystem)


@amqp_router.register("org_unit")
@amqp_reject_on_failure
async def process_org_unit(
    object_uuid: PayloadUUID,
    graphql_client: depends.GraphQLClient,
    amqpsystem: depends.AMQPSystem,
) -> None:
    await handle_org_unit(object_uuid, graphql_client, amqpsystem)


async def handle_org_unit(
    object_uuid: UUID,
    graphql_client: GraphQLClient,
    amqpsystem: MOAMQPSystem,
) -> None:
    logger.info("Registered change in an org_unit", object_uuid=object_uuid)
    # In case the name of the org-unit changed, we need to publish an
    # "engagement" message for each of its employees. Because org-unit
    # LDAP mapping is primarily done through the "Engagement" json-key.
    await graphql_client.org_unit_engagements_refresh(
        amqpsystem.exchange_name, object_uuid
    )


@asynccontextmanager
async def open_ldap_connection(ldap_connection: Connection) -> AsyncIterator[None]:
    """Open the LDAP connection during FastRAMQPI lifespan.

    Yields:
        None
    """
    with ldap_connection:
        yield


@asynccontextmanager
async def lifespan(
    fastramqpi: FastRAMQPI,
    settings: Settings,
) -> AsyncIterator[None]:
    async with AsyncExitStack() as stack:
        logger.info("Configuring LDAP connection")
        ldap_connection = configure_ldap_connection(settings)
        fastramqpi.add_context(ldap_connection=ldap_connection)
        fastramqpi.add_healthcheck(name="LDAPConnection", healthcheck=ldap_healthcheck)
        await stack.enter_async_context(open_ldap_connection(ldap_connection))

        context = fastramqpi.get_context()
        graphql_client: GraphQLClient = context["graphql_client"]

        logger.info("Initializing MOAPI")
        moapi = MOAPI(settings, graphql_client)

        logger.info("Initializing LDAPAPI")
        ldapapi = LDAPAPI(settings, ldap_connection)

        logger.info("Initializing username generator")
        username_generator = UserNameGenerator(settings, ldapapi.connection)

        logger.info("Initializing dataloader")
        dataloader = DataLoader(settings, moapi, ldapapi, username_generator)
        fastramqpi.add_context(dataloader=dataloader)

        logger.info("Initializing Import/Export checks")
        export_checks = ExportChecks(dataloader)
        import_checks = ImportChecks()

        logger.info("Initializing converters")
        amqpsystem = fastramqpi.get_amqpsystem()
        converter = LdapConverter(settings, dataloader, amqpsystem)
        fastramqpi.add_context(converter=converter)

        logger.info("Initializing Sync tool")
        sync_tool = SyncTool(
            dataloader,
            converter,
            export_checks,
            import_checks,
            settings,
            ldap_connection,
        )
        fastramqpi.add_context(sync_tool=sync_tool)

        logger.info("Starting AMQP listener")
        await stack.enter_async_context(amqpsystem)

        logger.info("Initializing LDAP listener")
        ldap_amqpsystem = configure_ldap_amqpsystem(fastramqpi, settings)
        await stack.enter_async_context(ldap_amqpsystem)
        if settings.listen_to_changes_in_ldap:
            logger.info("Initializing LDAP event generator")
            sessionmaker = fastramqpi.get_context()["sessionmaker"]
            ldap_event_generator = LDAPEventGenerator(
                sessionmaker, settings, ldap_amqpsystem, ldap_connection
            )
            fastramqpi.add_healthcheck(
                name="LDAPEventGenerator", healthcheck=ldap_event_generator.healthcheck
            )
            await stack.enter_async_context(ldap_event_generator)

        logger.info("Starting program")
        yield


class JinjaOutput(BaseModel, extra=Extra.forbid):
    dn: str
    create: bool
    attributes: dict[str, list[Any]]

    @validator("attributes", pre=True)
    def process_attributes(cls, v: dict[str, Any | None]) -> dict[str, list]:
        if not isinstance(v, dict):
            raise TypeError("attributes must be a dictionary")

        attributes = v
        # Convert None's to empty lists to avoid writing "None" in LDAP
        # Whenever a None is templated out we blank the value in LDAP
        attributes = {
            key: [] if value is None else value for key, value in attributes.items()
        }
        # Ensure that all values are lists
        attributes = {key: ensure_list(value) for key, value in attributes.items()}
        return attributes


def mo_to_ldap_handler(
    identifier: str,
    template_string: str,
    object_class: str,
) -> Callable:
    async def inner(
        exit_stack: depends.ExitStack,
        converter: depends.LdapConverter,
        dataloader: depends.DataLoader,
        event: Event[UUID],
    ) -> None:
        uuid = event.subject
        exit_stack.enter_context(
            bound_contextvars(identifier=identifier, uuid=str(uuid))
        )
        logger.info("Registered change in handler")

        template = converter.environment.from_string(template_string)
        result = await template.render_async({"uuid": uuid})
        logger.debug("Rendered jinja template", result=result)

        try:
            parsed = parse_raw_as(JinjaOutput, result)
        except json.JSONDecodeError as exc:
            message = "Unable to parse Jinja template output as JSON"
            logger.exception(message, result=result)
            raise HTTPException(status_code=500, detail=message) from exc
        except ValidationError as exc:
            message = "Unable to parse Jinja template output as model"
            logger.exception(message, result=result)
            raise HTTPException(status_code=500, detail=message) from exc

        logger.debug("Parsed jinja template", parsed=parsed)

        ldapapi = dataloader.ldapapi
        try:
            await ldapapi.ensure_ldap_object(
                parsed.dn, parsed.attributes, object_class, parsed.create
            )
        except NoObjectsReturnedException as exc:
            message = "Unable to find Jinja referenced dn"
            logger.exception(message)
            raise HTTPException(status_code=500, detail=message) from exc
        except LDAPUnwillingToPerformResult as exc:
            message = "The LDAP server was unwilling to perform the change"
            logger.exception(message)
            raise HTTPException(status_code=500, detail=message) from exc
        except LDAPObjectClassViolationResult as exc:
            message = "The LDAP server states that required attributes are missing"
            logger.exception(message)
            raise HTTPException(status_code=500, detail=message) from exc
        except LDAPNoSuchObjectResult as exc:
            message = "The LDAP server could not find the superior"
            logger.exception(message)
            raise HTTPException(status_code=500, detail=message) from exc

    return inner


def create_fastramqpi(**kwargs: Any) -> FastRAMQPI:
    """FastRAMQPI factory.

    Returns:
        FastRAMQPI system.
    """
    logger.info("Retrieving settings")
    settings = Settings(**kwargs)

    # ldap_ou_for_new_users needs to be in the search base. Otherwise we cannot
    # find newly created users...
    check_ou_in_list_of_ous(
        settings.ldap_ou_for_new_users,
        settings.ldap_ous_to_search_in,
    )

    # We also need to check for permission to write to this OU
    check_ou_in_list_of_ous(
        settings.ldap_ou_for_new_users,
        settings.ldap_ous_to_write_to,
    )

    logger.info("Setting up FastRAMQPI")
    fastramqpi = FastRAMQPI(
        application_name="ldap_ie",
        settings=settings.fastramqpi,
        graphql_version=GRAPHQL_VERSION,
        graphql_client_cls=GraphQLClient,
        database_metadata=Base.metadata,
        graphql_events=GraphQLEvents(
            declare_listeners=[
                # Configure dynamic listeners
                Listener(
                    namespace="mo",
                    user_key=mapping.identifier,
                    routing_key=mapping.routing_key,
                    path=f"/mo_to_ldap/{mapping.identifier}",
                )
                for mapping in settings.conversion_mapping.mo_to_ldap
            ]
            if settings.listen_to_changes_in_mo
            else []
        ),
    )
    fastramqpi.add_context(settings=settings)

    # Install dynamic endpoints router
    router = APIRouter(prefix="/mo_to_ldap")
    for mapping in settings.conversion_mapping.mo_to_ldap:
        handler = mo_to_ldap_handler(
            mapping.identifier, mapping.template, mapping.object_class
        )
        router.post(f"/{mapping.identifier}")(handler)
    app = fastramqpi.get_app()
    app.include_router(router)

    logger.info("AMQP router setup")
    amqpsystem = fastramqpi.get_amqpsystem()
    # Retry messages after a short period of time
    rate_limit_delay = 10
    amqpsystem.dependencies = [
        Depends(rate_limit(rate_limit_delay)),
        Depends(depends.logger_bound_message_id),
        Depends(depends.request_id),
    ]
    if settings.listen_to_changes_in_mo:
        amqpsystem.router.registry.update(amqp_router.registry)

    # We delay AMQPSystem start, to detect it from client startup
    # TODO: This separation should probably be in FastRAMQPI
    priority_set = fastramqpi._context["lifespan_managers"][1000]
    priority_set.remove(amqpsystem)

    fastramqpi.add_lifespan_manager(lifespan(fastramqpi, settings), 2000)

    return fastramqpi


def create_app(fastramqpi: FastRAMQPI | None = None, **kwargs: Any) -> FastAPI:
    """FastAPI application factory.

    Returns:
        FastAPI application.
    """
    if fastramqpi is None:
        fastramqpi = create_fastramqpi(**kwargs)
    assert fastramqpi is not None

    app = fastramqpi.get_app()
    settings = fastramqpi._context["user_context"]["settings"]
    app.include_router(construct_router(settings))
    app.include_router(mo2ldap_router)
    app.include_router(ldap2mo_router)
    app.include_router(ldap_event_router)

    return app
